{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "making catalogues to test within eazy\n",
    "opens ZFOURGE cat file, prepares it for dataframe, and some different catalogues are made (binning and such)\n",
    "then these are saved and can be used within the eazy code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "import eazy\n",
    "import astropy.stats\n",
    "\n",
    "\n",
    "field = 'cdfs'\n",
    "output = 'inputs/alternate_catalogues/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Adapting Template Files for EAZY\n",
    "\n",
    "# Set the directory\n",
    "in_dir = 'G:/AGN/hlsp_agnsedatlas_multi_multi_all_multi_v1_collection/templates_restframe/'\n",
    "out_dir = 'C:/Users/eddie/PycharmProjects/SEDTemplate_conda/templates/hlsp_agnsedatlas_rest/'\n",
    "\n",
    "# Get the txt files  in the directory\n",
    "txt_files = glob.glob(in_dir + '*.txt')\n",
    "\n",
    "for i in txt_files:\n",
    "\n",
    "    # Read the txt file\n",
    "    data = pd.read_csv(i, sep=\" \", comment='#', header=None, skipinitialspace=True)\n",
    "\n",
    "    data[0] = data[0] * 1e4 # Convert the wavelength from Micron to Angstroms\n",
    "    output_data = data[[0,2]]\n",
    "\n",
    "    # Get the base name of the txt file\n",
    "    base_name = os.path.basename(os.path.splitext(i)[0])\n",
    "\n",
    "    # Write the selected data to a dat file\n",
    "    output_data.to_csv(out_dir + f'{base_name}.dat', sep=' ', index=False, header=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the catalogues\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "# Get all cat files\n",
    "all_files = glob.glob(f'zfourge/{field}/{field}*.cat')\n",
    "\n",
    "# Check if any files were found\n",
    "if not all_files:\n",
    "  print(\"No .cat files found\")\n",
    "else:\n",
    "  # Find the shortest file by filename (assuming filename reflects size)\n",
    "  main_dir = min(all_files, key=len)\n",
    "\n",
    "main = pd.read_csv(main_dir, sep=\" \", comment=\"#\", header=None)\n",
    "headers = pd.read_csv(main_dir, sep=\" \", header=None, nrows=1).iloc[0]\n",
    "headers = headers[1:]\n",
    "main.columns = headers\n",
    "\n",
    "agn_data1 = glob.glob(f'zfourge/{field}/{field}.v*.agn.*cat')\n",
    "agn = pd.read_csv(agn_data1[0], sep=\"\\s+\", comment='#', header=None)\n",
    "headers = ['id', 'ir_agn', 'radio_agn','xray_agn']\n",
    "agn.columns = headers\n",
    "\n",
    "\n",
    "merged = pd.merge(main, agn, on='id', how='left')\n",
    "unwanted_hash = pd.Series(np.nan, index=merged.index, dtype=float)\n",
    "merged.insert(loc=0, column='#', value=unwanted_hash) #wierd hash at the start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Doing Specific Range Cuts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "object_range = (18000,20000)\n",
    "new_cat = merged[object_range[0]:object_range[1]]\n",
    "new_cat.to_csv(f'{output}{field}.range.{object_range}.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Doing Standard AGN Type Cuts, AGN type (Or wavelength) is not really as useful as the fraction of AGN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# ir_cut = merged[(merged['ir_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# radio_cut = merged[(merged['radio_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# xray_cut = merged[(merged['xray_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# all_cut = merged[(merged['ir_agn'] == 1) & (merged['z_spec'] > 0) | (merged['radio_agn'] == 1) & (merged['z_spec'] > 0) | (merged['xray_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# nothing_cut = merged[(merged['ir_agn'] != 1) & (merged['radio_agn'] != 1) & (merged['xray_agn'] != 1) & (merged['z_spec'] > 0)]\n",
    "\n",
    "ir_cut = merged[(merged['ir_agn'] == 1)]\n",
    "radio_cut = merged[(merged['radio_agn'] == 1)]\n",
    "xray_cut = merged[(merged['xray_agn'] == 1)]\n",
    "all_cut = merged[(merged['ir_agn'] == 1) | (merged['radio_agn'] == 1) | (merged['xray_agn'] == 1)]\n",
    "nothing_cut = merged[(merged['ir_agn'] != 1) & (merged['radio_agn'] != 1) & (merged['xray_agn'] != 1)]\n",
    "\n",
    "ir_cut.to_csv(f'{output}{field}.ir_agn.cat', sep=' ', index=False)\n",
    "radio_cut.to_csv(f'{output}{field}.radio_agn.cat', sep=' ', index=False)\n",
    "xray_cut.to_csv(f'{output}{field}.xray_agn.cat', sep=' ', index=False)\n",
    "all_cut.to_csv(f'{output}{field}.all_agn.cat', sep=' ', index=False)\n",
    "nothing_cut.to_csv(f'{output}{field}.no_agn.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the AGN Fraction file, and slimming it down, and creating keys from it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "agn_per_dir = 'inputs/results.txt' # THIS IS JUST CDFS, and a very big file\n",
    "all_bayes = pd.read_csv(agn_per_dir, sep=\"\\s+\", comment='#')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "new_bayes = all_bayes[['id', 'bayes.agn.fracAGN', 'bayes.agn.fracAGN_err', 'bayes.agn.luminosity']] # this is the information I want from this file\n",
    "new_bayes.to_csv(f'inputs/cdfs_agn_frac.txt', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bayes = pd.read_csv('inputs/cdfs_agn_frac.txt', sep=\"\\s+\", comment='#')\n",
    "merged_bayes = pd.merge(merged, bayes, on='id', how='left')\n",
    "fraction_sorted = merged_bayes.sort_values(by='bayes.agn.fracAGN', ascending=False)\n",
    "luminosity_sorted = merged_bayes.sort_values(by='bayes.agn.luminosity', ascending=False)\n",
    "num_rows = merged_bayes.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "num_bins = 3\n",
    "\n",
    "bins_frac = pd.cut(fraction_sorted['bayes.agn.fracAGN'], num_bins, labels=False)\n",
    "fraction_sorted['bin'] = bins_frac + 1\n",
    "bins_lum = pd.cut(luminosity_sorted['bayes.agn.luminosity'], num_bins, labels=False)\n",
    "luminosity_sorted['bin'] = bins_lum + 1\n",
    "\n",
    "#split fraction sorted into bins and save each as a separate df\n",
    "\n",
    "\n",
    "for bin_label in fraction_sorted['bin'].unique():\n",
    "  bin_df = fraction_sorted.query(\"bin == @bin_label\")  # Filter by bin label\n",
    "  bin_df = bin_df.drop(columns=['bin', 'bayes.agn.fracAGN', 'bayes.agn.fracAGN_err', 'bayes.agn.luminosity'])  # Drop the bin column\n",
    "  bin_df.to_csv(f'{output}{field}.fraction.bin{bin_label}.cat', sep=' ', index=False)\n",
    "\n",
    "for bin_label in luminosity_sorted['bin'].unique():\n",
    "    bin_df = luminosity_sorted.query(\"bin == @bin_label\")  # Filter by bin label\n",
    "    bin_df = bin_df.drop(columns=['bin', 'bayes.agn.fracAGN', 'bayes.agn.fracAGN_err', 'bayes.agn.luminosity'])  # Drop the bin column\n",
    "    bin_df.to_csv(f'{output}{field}.luminosity.bin{bin_label}.cat', sep=' ', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17920\n"
     ]
    }
   ],
   "source": [
    "#Only objects with a agn fraction above 0\n",
    "percent = 0.10\n",
    "only_agn = merged_bayes[merged_bayes['bayes.agn.fracAGN'] > percent]\n",
    "print(len(only_agn))\n",
    "only_agn.to_csv(f'{output}{field}.only_agn_above_{percent}.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking SED's of samples to slim Catalogues"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
