{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "making catalogues to test within eazy\n",
    "opens ZFOURGE cat file, prepares it for dataframe, and some different catalogues are made (binning and such)\n",
    "then these are saved and can be used within the eazy code\n",
    "Best to run this as separate cells, specified to your requirements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "import eazy\n",
    "import astropy.stats\n",
    "\n",
    "output = 'inputs/alternate_catalogues/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[164], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m in_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mG:/AGN/hlsp_agnsedatlas_multi_multi_all_multi_v1_collection/templates_restframe/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#out_dir = 'C:/Users/eddie/PycharmProjects/SEDTemplate_conda/templates/hlsp_agnsedatlas_rest/'\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[43mout_dir\u001B[49m):\n\u001B[0;32m      9\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(out_dir)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Get the txt files  in the directory\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Adapting Template Files for EAZY\n",
    "\n",
    "# Set the directory\n",
    "in_dir = 'G:/AGN/hlsp_agnsedatlas_multi_multi_all_multi_v1_collection/templates_restframe/'\n",
    "#out_dir = 'C:/Users/eddie/PycharmProjects/SEDTemplate_conda/templates/hlsp_agnsedatlas_rest/'\n",
    "\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Get the txt files  in the directory\n",
    "txt_files = glob.glob(in_dir + '*.txt')\n",
    "\n",
    "#txt_files = [i for i in txt_files if 'central' in i] # If you want the composite files\n",
    "\n",
    "for i in txt_files:\n",
    "\n",
    "    # Read the txt file\n",
    "    data = pd.read_csv(i, sep=\" \", comment='#', header=None, skipinitialspace=True)\n",
    "\n",
    "    data[0] = data[0] * 1e4 # Convert the wavelength from Micron to Angstroms\n",
    "    output_data = data[[0,2]]\n",
    "\n",
    "    # Get the base name of the txt file\n",
    "    base_name = os.path.basename(os.path.splitext(i)[0])\n",
    "\n",
    "    # Write the selected data to a dat file\n",
    "    output_data.to_csv(out_dir + f'{base_name}.dat', sep=' ', index=False, header=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Making any combined catalogues that cross multiple fields\n",
    "\n",
    "fields  = ['cdfs', 'cosmos', 'uds']\n",
    "\n",
    "main_dir_combined = []\n",
    "main_combined_all = []\n",
    "translate_all = []\n",
    "\n",
    "for idx, field in enumerate(fields):\n",
    "    all_catalogues = glob.glob(f'zfourge/{field}/{field}*.cat')\n",
    "\n",
    "        # Check if any files were found\n",
    "    if not all_catalogues:\n",
    "      print(f\"No .cat files found for {field}\")\n",
    "    else:\n",
    "      # Find the shortest file by filename\n",
    "      main_dir_combined.append(min(all_catalogues, key=len))\n",
    "\n",
    "    main = pd.read_csv(main_dir_combined[idx], sep=\" \", comment=\"#\", header=None)\n",
    "    headers = pd.read_csv(main_dir_combined[idx], sep=\" \", header=None, nrows=1).iloc[0]\n",
    "    headers = headers[1:]\n",
    "    main.columns = headers\n",
    "\n",
    "    agn_data1 = glob.glob(f'zfourge/{field}/{field}.v*.agn.*cat') # This is the agn file\n",
    "    agn = pd.read_csv(agn_data1[0], sep=\"\\s+\", comment='#', header=None)\n",
    "    headers = ['id', 'ir_agn', 'radio_agn','xray_agn']\n",
    "    agn.columns = headers\n",
    "\n",
    "\n",
    "    merged = pd.merge(main, agn, on='id', how='left')\n",
    "    unwanted_hash = pd.Series(np.nan, index=merged.index, dtype=float)\n",
    "    merged.insert(loc=0, column='#', value=unwanted_hash) #wierd hash at the start\n",
    "\n",
    "    main_combined_all.append(merged)\n",
    "\n",
    "    # Also need to make a new translate file\n",
    "    translate_file = glob.glob(f'zfourge/{field}/eazy/{field}.*.translate') # again this glob function will need some customisation\n",
    "    translate = pd.read_csv(translate_file[0], sep='\\s+', header=None, usecols=range(2))\n",
    "    translate_all.append(translate)\n",
    "\n",
    "main_combined = pd.concat(main_combined_all, ignore_index=True)\n",
    "main_combined['id'] = main_combined.index + 1\n",
    "\n",
    "translate_final = pd.concat(translate_all, ignore_index=True)\n",
    "translate_final = translate_final.drop_duplicates(keep='first')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isdir('zfourge/combined/eazy'):\n",
    "    os.makedirs('zfourge/combined/eazy')\n",
    "\n",
    "translate_final.to_csv('zfourge/combined/eazy/combined.1.0.translate', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Columns to exclude\n",
    "exclude_cols = ['#']\n",
    "# Replace NaN with -99 for all columns except excluded columns\n",
    "main_combined.loc[:, ~main_combined.columns.isin(exclude_cols)] = main_combined.loc[:, ~main_combined.columns.isin(exclude_cols)].fillna(-99)\n",
    "\n",
    "# move agn columns to the end so that nan values are not in the middle of the file\n",
    "agn_cols = ['star', 'nearstar', 'use', 'snr', 'use_nosnr', 'z_spec', 'ir_agn', 'radio_agn', 'xray_agn']\n",
    "\n",
    "main_combined = main_combined[[col for col in main_combined if col not in agn_cols] + [col for col in agn_cols]]\n",
    "main_combined.to_csv(f'{output}combined.normal.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start here if you have made the combined catalogue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "# Load the catalogues\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "field = 'uds'\n",
    "\n",
    "# Get all cat files\n",
    "all_files = glob.glob(f'zfourge/{field}/{field}*.cat')\n",
    "\n",
    "# Check if any files were found\n",
    "if not all_files:\n",
    "  print(\"No .cat files found\")\n",
    "else:\n",
    "  # Find the shortest file by filename\n",
    "  main_dir = min(all_files, key=len)\n",
    "\n",
    "main = pd.read_csv(main_dir, sep=\" \", comment=\"#\", header=None)\n",
    "headers = pd.read_csv(main_dir, sep=\" \", header=None, nrows=1).iloc[0]\n",
    "headers = headers[1:]\n",
    "main.columns = headers\n",
    "\n",
    "agn_data1 = glob.glob(f'zfourge/{field}/{field}.v*.agn.*cat')\n",
    "agn = pd.read_csv(agn_data1[0], sep=\"\\s+\", comment='#', header=None)\n",
    "headers = ['id', 'ir_agn', 'radio_agn','xray_agn']\n",
    "agn.columns = headers\n",
    "\n",
    "\n",
    "merged = pd.merge(main, agn, on='id', how='left')\n",
    "unwanted_hash = pd.Series(np.nan, index=merged.index, dtype=float)\n",
    "merged.insert(loc=0, column='#', value=unwanted_hash) #wierd hash at the start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving the Catalogue file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged.to_csv(f'{output}{field}.normal.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of this dataframe is: 11183\n"
     ]
    }
   ],
   "source": [
    "useflag_df  = merged[merged['use'] == 1]\n",
    "useflag_df.to_csv(f'{output}{field}.useflag.cat', sep=' ', index=False)\n",
    "print(f'the size of this dataframe is: {len(useflag_df)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Doing Specific Range Cuts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "object_range = (0,-0)\n",
    "new_cat = merged[object_range[0]:object_range[1]]\n",
    "new_cat.to_csv(f'{output}{field}.range.{object_range}.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Doing Standard AGN Type Cuts, AGN type (Or wavelength) is not really as useful as the fraction of AGN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ir_cut = merged[(merged['ir_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# radio_cut = merged[(merged['radio_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# xray_cut = merged[(merged['xray_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# all_cut = merged[(merged['ir_agn'] == 1) & (merged['z_spec'] > 0) | (merged['radio_agn'] == 1) & (merged['z_spec'] > 0) | (merged['xray_agn'] == 1) & (merged['z_spec'] > 0)]\n",
    "# nothing_cut = merged[(merged['ir_agn'] != 1) & (merged['radio_agn'] != 1) & (merged['xray_agn'] != 1) & (merged['z_spec'] > 0)]\n",
    "\n",
    "ir_cut = merged[(merged['ir_agn'] == 1)]\n",
    "radio_cut = merged[(merged['radio_agn'] == 1)]\n",
    "xray_cut = merged[(merged['xray_agn'] == 1)]\n",
    "all_cut = merged[(merged['ir_agn'] == 1) | (merged['radio_agn'] == 1) | (merged['xray_agn'] == 1)]\n",
    "nothing_cut = merged[(merged['ir_agn'] != 1) & (merged['radio_agn'] != 1) & (merged['xray_agn'] != 1)]\n",
    "\n",
    "ir_cut.to_csv(f'{output}{field}.ir_agn.cat', sep=' ', index=False)\n",
    "radio_cut.to_csv(f'{output}{field}.radio_agn.cat', sep=' ', index=False)\n",
    "xray_cut.to_csv(f'{output}{field}.xray_agn.cat', sep=' ', index=False)\n",
    "all_cut.to_csv(f'{output}{field}.all_agn.cat', sep=' ', index=False)\n",
    "nothing_cut.to_csv(f'{output}{field}.no_agn.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the AGN Fraction file, and slimming it down, and creating keys from it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the CIGALE results file\n",
    "agn_per_dir = f'inputs/{field}_results.txt' # large file\n",
    "all_bayes = pd.read_csv(agn_per_dir, sep=\"\\s+\", comment='#')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_bayes = all_bayes[['id', 'bayes.agn.fracAGN', 'bayes.agn.fracAGN_err', 'bayes.agn.luminosity']] # this is the information I want from this file\n",
    "new_bayes.to_csv(f'inputs/{field}_agn_frac.txt', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#making combined bayes file\n",
    "all_agn_data = []\n",
    "for field in fields:\n",
    "    agn_data = pd.read_csv(f'inputs/{field}_agn_frac.txt', sep=\"\\s+\", comment='#')\n",
    "    all_agn_data.append(agn_data)\n",
    "\n",
    "all_agn_data = pd.concat(all_agn_data, ignore_index=True)\n",
    "all_agn_data['id'] = all_agn_data.index + 1\n",
    "all_agn_data.to_csv(f'inputs/combined_agn_frac.txt', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merging the AGN fraction file with the main catalogue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bayes = pd.read_csv(f'inputs/{field}_agn_frac.txt', sep=\"\\s+\", comment='#')\n",
    "merged_bayes = pd.merge(merged, bayes, on='id', how='left')\n",
    "fraction_sorted = merged_bayes.sort_values(by='bayes.agn.fracAGN', ascending=False)\n",
    "luminosity_sorted = merged_bayes.sort_values(by='bayes.agn.luminosity', ascending=False)\n",
    "num_rows = merged_bayes.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AGN Bins, usually have 10 bins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_bins = 10\n",
    "fraction_range = 100/num_bins\n",
    "\n",
    "#split fraction sorted into bins and save each as a separate df\n",
    "\n",
    "for bin_no in range(num_bins):\n",
    "    min_bin = (bin_no * fraction_range) / 100\n",
    "    max_bin = ((bin_no+1) * fraction_range) / 100\n",
    "    bin_df = fraction_sorted[(min_bin <= fraction_sorted['bayes.agn.fracAGN']) &\n",
    "                             (fraction_sorted['bayes.agn.fracAGN'] <= max_bin)]\n",
    "    bin_df.to_csv(f'{output}{field}.fraction.bin{min_bin}to{max_bin}.cat', sep=' ', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Only objects with an agn fraction above percent\n",
    "percent = 0.50\n",
    "only_agn = merged_bayes[merged_bayes['bayes.agn.fracAGN'] >= percent]\n",
    "print(len(only_agn))\n",
    "only_agn.to_csv(f'{output}{field}.only_agn_above_{percent}.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lacy wedge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set field again\n",
    "is_it_combined = False\n",
    "if is_it_combined:\n",
    "    lacy_init_df = main_combined[['f_IRAC_58', 'e_IRAC_58', 'f_IRAC_36', 'e_IRAC_36', 'f_IRAC_80', 'e_IRAC_80', 'f_IRAC_45', 'e_IRAC_45', 'bayes.agn.fracAGN']]\n",
    "else:\n",
    "    lacy_init_df = merged_bayes[['f_IRAC_58', 'e_IRAC_58', 'f_IRAC_36', 'e_IRAC_36', 'f_IRAC_80', 'e_IRAC_80', 'f_IRAC_45', 'e_IRAC_45', 'bayes.agn.fracAGN']]\n",
    "cut_by_negative_lacy = (lacy_init_df['f_IRAC_58'] > -0) &\\\n",
    "                       (lacy_init_df['f_IRAC_36'] > -0) &\\\n",
    "                       (lacy_init_df['f_IRAC_80'] > -0) &\\\n",
    "                       (lacy_init_df['f_IRAC_45'] > -0)\n",
    "lacy_init_df = lacy_init_df[cut_by_negative_lacy]\n",
    "\n",
    "cut_by_error_lacy = (lacy_init_df['f_IRAC_58'] > 3 * lacy_init_df['e_IRAC_58']) &\\\n",
    "                    (lacy_init_df['f_IRAC_36'] > 3 * lacy_init_df['e_IRAC_36']) &\\\n",
    "                    (lacy_init_df['f_IRAC_80'] > 3 * lacy_init_df['e_IRAC_80']) &\\\n",
    "                    (lacy_init_df['f_IRAC_45'] > 3 * lacy_init_df['e_IRAC_45'])\n",
    "\n",
    "#lacy_init_df = lacy_init_df[cut_by_error_lacy]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lacy_df = pd.DataFrame()\n",
    "lacy_df['58'] = lacy_init_df['f_IRAC_58']\n",
    "lacy_df['36'] = lacy_init_df['f_IRAC_36']\n",
    "lacy_df['80'] = lacy_init_df['f_IRAC_80']\n",
    "lacy_df['45'] = lacy_init_df['f_IRAC_45']\n",
    "lacy_df['agn'] = lacy_init_df['bayes.agn.fracAGN']\n",
    "\n",
    "lacy_df['x'] = np.log10(lacy_df['58']/lacy_df['36'])\n",
    "lacy_df['y'] = np.log10(lacy_df['80']/lacy_df['45'])\n",
    "\n",
    "cut = (lacy_df['x'] > -0.1) & (-0.2 < lacy_df['y']) & (lacy_df['y'] < (0.8 * lacy_df['x'] + 0.5))\n",
    "lacy_in = lacy_df[cut]\n",
    "lacy_out = lacy_df[~cut]\n",
    "\n",
    "common_index = merged.index.intersection(lacy_in.index)\n",
    "lacy_cat = merged.loc[common_index]\n",
    "\n",
    "#lacy_cat.to_csv(f'{output}{field}.lacy_wedge.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(lacy_in['x'], lacy_in['y'], c=lacy_in['agn'], cmap='inferno', marker='.', alpha=0.5)\n",
    "plt.scatter(lacy_out['x'], lacy_out['y'], c=lacy_out['agn'], cmap='inferno', marker='.', alpha=0.5)\n",
    "\n",
    "x_boundary = np.linspace(-0.1, 2, 100)  # Adjust range as needed\n",
    "y_boundary1 = -0.2 * np.ones_like(x_boundary)\n",
    "y_boundary2 = 0.8 * x_boundary + 0.5\n",
    "y_line = np.linspace(-0.2, 0.4, 100)\n",
    "plt.plot(x_boundary, y_boundary1, color='red', linestyle='--')\n",
    "plt.plot(x_boundary, y_boundary2, color='red', linestyle='--')\n",
    "plt.plot(-0.1 * np.ones_like(y_line), y_line, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('log(f58/f36)')\n",
    "plt.ylabel('log(f80/f45)')\n",
    "plt.title('Lacy Wedge')\n",
    "plt.colorbar()\n",
    "plt.xlim(-0.6, 0.8)\n",
    "plt.ylim(-1.2, 1.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cut_donley = (lacy_df['x'] >= 0.08) & (lacy_df['y'] >= 0.15) & (lacy_df['y'] >= (1.21 * lacy_df['x']) - 0.27) & (lacy_df['y'] <= (1.21 * lacy_df['x']) + 0.27) & (lacy_df['80'] > lacy_df['58']) & (lacy_df['58'] > lacy_df['45']) & (lacy_df['45'] > lacy_df['36'])\n",
    "\n",
    "donley_in = lacy_df[cut_donley]\n",
    "donley_out = lacy_df[~cut_donley]\n",
    "\n",
    "common_index = merged.index.intersection(donley_in.index)\n",
    "lacy_cat = merged.loc[common_index]\n",
    "#lacy_cat.to_csv(f'{output}{field}.donley_wedge.cat', sep=' ', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(donley_in['x'], donley_in['y'], c=donley_in['agn'], cmap='inferno', marker='.', alpha=0.5)\n",
    "plt.scatter(donley_out['x'], donley_out['y'], c=donley_out['agn'], cmap='inferno', marker='.', alpha=0.5)\n",
    "\n",
    "x_boundary = np.linspace(-0.1, 2, 100)  # Adjust range as needed\n",
    "y_boundary1 = -0.2 * np.ones_like(x_boundary)\n",
    "y_boundary2 = 0.8 * x_boundary + 0.5\n",
    "y_line = np.linspace(-0.2, 0.4, 100)\n",
    "plt.plot(x_boundary, y_boundary1, color='red', linestyle='--')\n",
    "plt.plot(x_boundary, y_boundary2, color='red', linestyle='--')\n",
    "plt.plot(-0.1 * np.ones_like(y_line), y_line, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('log(f58/f36)')\n",
    "plt.ylabel('log(f80/f45)')\n",
    "plt.title('Lacy(Red) and Donely (Pink) Wedge')\n",
    "plt.colorbar()\n",
    "plt.xlim(-0.6, 0.8)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "\n",
    "# Define functions for boundary lines\n",
    "def line1(x):\n",
    "    return 1.21 * x - 0.27\n",
    "def line2(x):\n",
    "    return 1.21 * x + 0.27\n",
    "\n",
    "# Generate x values for plotting lines\n",
    "x_values1 = np.linspace(0.08, max(lacy_df['x']), 100)\n",
    "x_values2 = np.linspace(0.35, max(lacy_df['x']), 100)\n",
    "\n",
    "# Plot the lines\n",
    "plt.plot(x_values2, line1(x_values2), color='magenta', linestyle='--')\n",
    "plt.plot(x_values1, line2(x_values1), color='magenta', linestyle='--')\n",
    "plt.plot(np.linspace(0.08, 0.35, 10), np.linspace(0.15, 0.15, 10), color='magenta', linestyle='--')\n",
    "plt.plot(np.linspace(0.08, 0.08, 10), np.linspace(0.15, 0.35, 10), color='magenta', linestyle='--')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making a synthetic catalogue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dir = 'inputs/synthetic_templates/'\n",
    "all_templates  = glob.glob(f'{input_dir}*.sed')\n",
    "all_templates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for template in all_templates:\n",
    "    template_data = pd.read_csv(template, sep='\\s+', header=None)\n",
    "    id_temp = template.split('\\\\')[-1].split('.')[0]\n",
    "    plt.plot(template_data[0], template_data[1], label=id_temp)\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"center left\", borderaxespad=0)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Wavelength (Angstrom)')\n",
    "plt.ylabel('Flux/F6000')\n",
    "plt.title('AGN Templates')\n",
    "plt.xlim(900, 35e4)\n",
    "plt.ylim(1e-2, 1e3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mrk231 = [s for s in all_templates if \"mrk231\" in s.lower()]\n",
    "mrk231 = mrk231[0]\n",
    "mrk231"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "other_dir = 'templates/hlsp_agnsedatlas_rest/'\n",
    "all_templates  = glob.glob(f'{other_dir}*.dat')\n",
    "mrk231_2 = [s for s in all_templates if \"mrk231\" in s]\n",
    "mrk231_2 = mrk231_2[0]\n",
    "template_data_1 = pd.read_csv(mrk231, sep='\\s+', header=None)\n",
    "template_data_2 = pd.read_csv(mrk231_2, sep='\\s+', header=None)\n",
    "plt.plot(template_data_1[0], template_data_1[1], label='1')\n",
    "flux_position =  abs(template_data_2[0] - 6000).idxmin()\n",
    "flux_normal = template_data_2[1][flux_position]\n",
    "plt.plot(template_data_2[0], template_data_2[1] / flux_normal, label='2')\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"center left\", borderaxespad=0)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Wavelength (Angstrom)')\n",
    "plt.ylabel('Flux/F6000')\n",
    "plt.title('MRK 231')\n",
    "plt.xlim(900, 35e4)\n",
    "plt.ylim(1e-2, 1e3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agn_templates = ['Sey2', 'Sey1.8', 'QSO2', 'Torus', 'QSO1', 'BQSO1', 'TQSO1'] # which of the templates are of AGNs\n",
    "composite_templates = ['IRAS19254-7245 South ', 'Mrk231'] # which of the templates are composite, and won't be used\n",
    "galaxy_templates = [n for n in all_templates if n not in agn_templates and n not in composite_templates]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def agn_fraction(a,b,f):\n",
    "    return a * np.exp(-f/b)\n",
    "\n",
    "x_model = np.linspace(0,1,1000)\n",
    "y_model = agn_fraction(1, 0.1, x_model)\n",
    "\n",
    "plt.plot(x_model, y_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agn_per_dir = f'inputs/cdfs_agn_frac.txt'\n",
    "all_bayes = pd.read_csv(agn_per_dir, sep=\"\\s+\", comment='#')\n",
    "plt.clf()\n",
    "bins_count = 100\n",
    "(n, bins, patches) = plt.hist(all_bayes['bayes.agn.fracAGN'], bins=bins_count, label='AGN Fraction')\n",
    "\n",
    "plt.xlabel('AGN Fraction')\n",
    "plt.ylabel('Number of Objects')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def log(x,a,b,c,d):\n",
    "    return a * np.log10(b * x + c) + d\n",
    "\n",
    "x_data = np.linspace(0,1,int(bins_count))\n",
    "y_data = n / n.sum()\n",
    "popt, pcov = curve_fit(log, x_data, y_data, p0=[-0.05, 1, 0.0005, 0])\n",
    "\n",
    "x_mdoel = np.linspace(0,1,1000)\n",
    "y_model = log(x_model, *popt)\n",
    "\n",
    "plt.plot(x_data, y_data, label='Data')\n",
    "plt.plot(x_model, y_model, label=f'Model, {popt}')\n",
    "plt.xlabel('AGN Fraction')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def agn_fractioner(fraction):\n",
    "    # combined templates based on the given fraction.\n",
    "    print('ok')\n",
    "\n",
    "fraction_per = []\n",
    "for i in range(bins_count):\n",
    "    fraction_per.append(log(i, *popt))\n",
    "plt.plot(x_data, fraction_per)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "no_of_galaxies = 10000\n",
    "\n",
    "agn_fractions = []\n",
    "x_intercept_log = log(0, *popt)\n",
    "x_intercept_inv = inverse_log(0, *popt)\n",
    "for i in range(no_of_galaxies):\n",
    "    agn_frac = inverse_log(np.random.rand() * x_intercept_log, a_opt, b_opt, c_opt, d_opt)\n",
    "    agn_fractions.append(agn_frac)\n",
    "\n",
    "plt.hist(agn_fractions, bins=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(inverse_log(np.random.rand() * x_intercept_log, a_opt, b_opt, c_opt, d_opt), 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
